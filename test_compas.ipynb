{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2.0 in /opt/homebrew/lib/python3.11/site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy<1.13.0 in /opt/homebrew/lib/python3.11/site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/homebrew/lib/python3.11/site-packages (from scipy<1.13.0) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: fastsparsegams in /opt/homebrew/lib/python3.11/site-packages (0.1.2)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/homebrew/lib/python3.11/site-packages (from fastsparsegams) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/homebrew/lib/python3.11/site-packages (from fastsparsegams) (1.11.4)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/homebrew/lib/python3.11/site-packages (from fastsparsegams) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.11/site-packages (from fastsparsegams) (3.9.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/JudyWork/Library/Python/3.11/lib/python/site-packages (from pandas>=1.0.0->fastsparsegams) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=1.0.0->fastsparsegams) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=1.0.0->fastsparsegams) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->fastsparsegams) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->fastsparsegams) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->fastsparsegams) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->fastsparsegams) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->fastsparsegams) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->fastsparsegams) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->fastsparsegams) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->fastsparsegams) (3.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install 'numpy<2.0'\n",
    "%pip install 'scipy<1.13.0'\n",
    "%pip install fastsparsegams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fastsparsegams\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_continuous_df_to_binary_df(df):\n",
    "    \"\"\"Convert continuous features to binary features in the dataframe.\n",
    "\n",
    "    Generates 100 percentile thresholds for each feature.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The input dataframe containing continuous features.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The binary dataframe with converted features.\n",
    "    \"\"\"\n",
    "    colnames = df.columns\n",
    "    n = len(df)\n",
    "    print(\"Make sure your first column corresponds to the y label\")\n",
    "    print(\"Converting continuous features to binary features in the dataframe......\")\n",
    "\n",
    "    percentile_ticks = range(1, 101)\n",
    "\n",
    "    binarized_dict = {}\n",
    "\n",
    "    for i in range(0, len(colnames)):\n",
    "        uni = df[colnames[i]].unique()\n",
    "        if len(uni) == 2:\n",
    "            binarized_dict[colnames[i]] = np.asarray(df[colnames[i]], dtype=int)\n",
    "            continue\n",
    "\n",
    "        uni.sort()\n",
    "        if len(uni) >= 100:\n",
    "            uni = np.percentile(uni, percentile_ticks)\n",
    "        for j in range(len(uni) - 1):\n",
    "            tmp_feature = np.ones(n, dtype=int)\n",
    "            tmp_name = colnames[i] + \"<=\" + str(uni[j])\n",
    "\n",
    "            zero_indices = df[colnames[i]] > uni[j]\n",
    "            tmp_feature[zero_indices] = 0\n",
    "\n",
    "            binarized_dict[tmp_name] = tmp_feature\n",
    "\n",
    "    binarized_df = pd.DataFrame(binarized_dict)\n",
    "    print(\"Finish converting continuous features to binary features......\")\n",
    "    return binarized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shape_functions_fastsparse(gam, binary_cols, continuous_df, lambda_0=0):\n",
    "    \"\"\"Plot the shape functions of a GAM model using the fastsparse package.\n",
    "\n",
    "    Parameters:\n",
    "        gam: The trained GAM model.\n",
    "        binary_cols: The binary column names used in the GAM model.\n",
    "        continuous_df: The continuous dataframe used in the GAM model.\n",
    "        lambda_0 (float, optional): The regularization parameter. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    gam_coeffs = gam.coeff(lambda_0=lambda_0)\n",
    "    intercept = gam_coeffs[0]\n",
    "    coefficients = gam_coeffs[1:]\n",
    "    used_binary_features = binary_cols[coefficients.indices]  # of form \"feature_name<=threshold\"\n",
    "    feature_names = np.unique([feature.split(\"<=\")[0] for feature in used_binary_features])\n",
    "    print(intercept)\n",
    "    for feature_name in feature_names:\n",
    "        feature_indices = []\n",
    "        for i, feature in enumerate(used_binary_features):\n",
    "            if feature_name in feature:\n",
    "                feature_indices.append(i)\n",
    "\n",
    "        feature_min = continuous_df[feature_name].min()\n",
    "        feature_max = continuous_df[feature_name].max()\n",
    "        steps = [float(feature.split(\"<=\")[1]) for feature in used_binary_features[feature_indices]]\n",
    "        steps = [feature_min] + steps + [feature_max]\n",
    "\n",
    "        coefficients_lte = gam_coeffs.data[feature_indices]\n",
    "        coefficients_lte_steps = convert_coefficients_to_shape_function(coefficients_lte, direction=\"<\")\n",
    "        coefficients = coefficients_lte_steps\n",
    "\n",
    "\n",
    "        plot_shape_function(steps, coefficients, feature_name)\n",
    "def convert_coefficients_to_shape_function(coefficients, direction=\"<\"):\n",
    "    \"\"\"Convert the gam feature coefficients to a step/shape function.\n",
    "\n",
    "    This is needed to make the coefficient representation conform to the\n",
    "    alignment expectations of plt.step, which are somewhat unintuitive.\n",
    "    You can figure out how to do this yourself with a whiteboard and some patience,\n",
    "    but I did that for you :)\n",
    "\n",
    "    Parameters:\n",
    "        coefficients (list[float]): The coefficients of the shape function.\n",
    "        direction (str, optional): The direction of the step function.\n",
    "            Can be \"<\" or \">\". Defaults to \"<\".\n",
    "\n",
    "    Returns:\n",
    "        list[float]: The step function coefficients.\n",
    "    \"\"\"\n",
    "    coefficients_steps = np.zeros(len(coefficients)+2)\n",
    "    if direction == \"<\":\n",
    "        coeff_reverse_cumsum = np.cumsum(coefficients[::-1])[::-1]\n",
    "        coefficients_steps[1:-1] = coeff_reverse_cumsum\n",
    "        coefficients_steps[0] = coeff_reverse_cumsum[0]\n",
    "    else:\n",
    "        coeff_cumsum = np.cumsum(coefficients)\n",
    "        coefficients_steps[2:] = coeff_cumsum\n",
    "    return coefficients_steps\n",
    "def plot_shape_function(steps: list[float], coefficients: list[float], feature_name: str, ax=None):\n",
    "    \"\"\"Plot the shape function of the GAM for a single feature.\n",
    "\n",
    "    The shape function is a piecewise constant function that is the sum of the coefficients\n",
    "    where the feature value is less than or equal to the step (or greater than).\n",
    "\n",
    "    Parameters:\n",
    "        steps (list[float]): The steps in the shape function. Assume these are sorted in ascending order.\n",
    "        coefficients (list[float]): The coefficients of the shape function.\n",
    "        feature_name (str): The name of the feature.\n",
    "        ax (matplotlib.axes.Axes, optional): The axes on which to plot the shape function.\n",
    "            If not provided, a new figure and axes will be created.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    ax.step(steps, coefficients, where=\"pre\")\n",
    "    ax.set_xlabel(feature_name)\n",
    "    ax.set_ylabel(\"Shape function\")\n",
    "    ax.set_title(f\"Shape function for {feature_name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/JudyWork/Desktop/Research/474-GAMS/comparisons/datasets/compas.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Extract features and target\n",
    "X = df.drop('two_year_recid', axis=1).astype(np.float64)\n",
    "y = df['two_year_recid'] # Convert to binary: 1 for 'Good', 0 for 'Bad'\n",
    "\n",
    "# split into 15% test, 10% validation, 75% train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1/(1-.15), random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure your first column corresponds to the y label\n",
      "Converting continuous features to binary features in the dataframe......\n",
      "Finish converting continuous features to binary features......\n"
     ]
    }
   ],
   "source": [
    "binary_df = convert_continuous_df_to_binary_df(pd.concat([y, X], axis=1))\n",
    "X_binary = binary_df[binary_df.columns[1:]]\n",
    "y_binary = binary_df[binary_df.columns[0]]\n",
    "\n",
    "X_binary_train = X_binary.iloc[X_train.index]\n",
    "y_binary_train = y_binary.iloc[X_train.index]\n",
    "\n",
    "X_binary_val = X_binary.iloc[X_val.index]\n",
    "y_binary_val = y_binary.iloc[X_val.index]\n",
    "\n",
    "X_binary_test = X_binary.iloc[X_test.index]\n",
    "y_binary_test = y_binary.iloc[X_test.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fsg = X_binary_train.values.astype(float)\n",
    "y_train_fsg = y_binary_train.values\n",
    "\n",
    "X_test_fsg = X_binary_test.values.astype(float)\n",
    "y_test_fsg = y_binary_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train finished in 0.5233809947967529s\n",
      "train finished in 0.5177128314971924s\n",
      "train finished in 0.39497923851013184s\n",
      "train finished in 0.23595786094665527s\n",
      "train finished in 0.3476111888885498s\n",
      "train finished in 0.18044519424438477s\n",
      "train finished in 0.15326786041259766s\n",
      "train finished in 0.15261387825012207s\n",
      "train finished in 0.44357728958129883s\n",
      "train finished in 0.3282947540283203s\n",
      "train finished in 0.23978805541992188s\n",
      "train finished in 0.1278247833251953s\n",
      "train finished in 0.15177392959594727s\n",
      "train finished in 0.13364100456237793s\n",
      "train finished in 0.1194460391998291s\n",
      "train finished in 0.11337995529174805s\n",
      "Results logged to fastsparseresults.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "lambdas = [0.8, 1, 2, 3, 4, 5, 6, 7]\n",
    "gammas = [0.00001, 0.001]\n",
    "penalty_type = \"L0L2\"\n",
    "ell = \"Logistic\"\n",
    "results = []\n",
    "\n",
    "for g in gammas:\n",
    "    for l in lambdas:\n",
    "        \n",
    "        start_time = time.time()\n",
    "    \n",
    "        # Fit GAM model\n",
    "        model = fastsparsegams.fit(\n",
    "            X_train_fsg, \n",
    "            y_train_fsg, \n",
    "            algorithm=\"CDPSI\",\n",
    "            penalty=penalty_type,\n",
    "            loss=ell,\n",
    "            lambda_grid=np.array([[l]]),\n",
    "            num_gamma=None,\n",
    "            num_lambda=None,\n",
    "            gamma_max=g,\n",
    "            gamma_min=g\n",
    "        )\n",
    "        \n",
    "        # Measure fitting time\n",
    "        end_time = time.time()\n",
    "        train_time = end_time-start_time\n",
    "        print(f\"train finished in {train_time}s\")\n",
    "        \n",
    "        for i, lambda_val in enumerate(model.characteristics()[\"l0\"]):\n",
    "            support_size = model.characteristics()[\"support_size\"][i]\n",
    "            beta = model.coeff(lambda_0=lambda_val, gamma=g)\n",
    "            \n",
    "            intercept, b = beta[0], beta[1:]\n",
    "            y_pred_train = model.predict(X_train_fsg, lambda_0=lambda_val, gamma=g)\n",
    "            y_pred_test = model.predict(X_test_fsg, lambda_0=lambda_val, gamma=g)\n",
    "\n",
    "            auc_train = roc_auc_score(y_train_fsg, y_pred_train)\n",
    "            auc_test = roc_auc_score(y_test_fsg, y_pred_test)\n",
    "            acc_train = accuracy_score(y_train_fsg, (y_pred_train >= 0.5).astype(int))\n",
    "            acc_test = accuracy_score(y_test_fsg, (y_pred_test >= 0.5).astype(int))\n",
    "\n",
    "            result = [\"fastsparse\", ell, penalty_type, lambda_val, g, support_size, \n",
    "                        auc_train, auc_test, acc_train, acc_test, train_time]\n",
    "            results.append(result)\n",
    "\n",
    "log_file = \"fastsparseresults.csv\"\n",
    "df = pd.DataFrame(results, columns=[\n",
    "        \"algorithm\", \"loss\", \"penalty_type\",\n",
    "        \"lambda\", \"gamma\", \"support_size\", \"auc_train\", \"auc_test\", \"acc_train\", \"acc_test\", \"train_time\"\n",
    "    ])\n",
    "df.to_csv(log_file, mode=\"a\", header=True, index=False, float_format=\"%.6f\")\n",
    "print(\"Results logged to\", log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting GAM with 100 smoothing parameters...\n",
      "Best accuracy: 0.6931982633863966, AUC: 0.691851106639839, lambda_0: 0.04848317386989738, support size: 39\n",
      "  (0, 0)\t0.899953473641773\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 52\u001b[0m\n\u001b[1;32m     48\u001b[0m             best_auc \u001b[38;5;241m=\u001b[39m val_auc\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_val_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_auc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, lambda_0: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_lambda\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, support size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_support_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m     \u001b[43mplot_shape_functions_fastsparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_binary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontinuous_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_lambda\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Print fitting times\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFitting Times (seconds):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m, in \u001b[0;36mplot_shape_functions_fastsparse\u001b[0;34m(gam, binary_cols, continuous_df, lambda_0)\u001b[0m\n\u001b[1;32m     25\u001b[0m feature_min \u001b[38;5;241m=\u001b[39m continuous_df[feature_name]\u001b[38;5;241m.\u001b[39mmin()\n\u001b[1;32m     26\u001b[0m feature_max \u001b[38;5;241m=\u001b[39m continuous_df[feature_name]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m---> 27\u001b[0m steps \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mused_binary_features\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     28\u001b[0m steps \u001b[38;5;241m=\u001b[39m [feature_min] \u001b[38;5;241m+\u001b[39m steps \u001b[38;5;241m+\u001b[39m [feature_max]\n\u001b[1;32m     30\u001b[0m coefficients_lte \u001b[38;5;241m=\u001b[39m gam_coeffs\u001b[38;5;241m.\u001b[39mdata[feature_indices]\n",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     25\u001b[0m feature_min \u001b[38;5;241m=\u001b[39m continuous_df[feature_name]\u001b[38;5;241m.\u001b[39mmin()\n\u001b[1;32m     26\u001b[0m feature_max \u001b[38;5;241m=\u001b[39m continuous_df[feature_name]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m---> 27\u001b[0m steps \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m used_binary_features[feature_indices]]\n\u001b[1;32m     28\u001b[0m steps \u001b[38;5;241m=\u001b[39m [feature_min] \u001b[38;5;241m+\u001b[39m steps \u001b[38;5;241m+\u001b[39m [feature_max]\n\u001b[1;32m     30\u001b[0m coefficients_lte \u001b[38;5;241m=\u001b[39m gam_coeffs\u001b[38;5;241m.\u001b[39mdata[feature_indices]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "max_support_sizes = [100]\n",
    "\n",
    "fit_times = {}\n",
    "\n",
    "\n",
    "for sp in max_support_sizes:\n",
    "   \n",
    "    print(f\"\\nFitting GAM with {sp} smoothing parameters...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fit GAM model\n",
    "    gam = fastsparsegams.fit(\n",
    "        X_train_fsg, \n",
    "        y_train_fsg, \n",
    "        algorithm=\"CDPSI\",\n",
    "        penalty='L0',\n",
    "        loss='Exponential',\n",
    "        max_support_size=sp,\n",
    "    )\n",
    "    \n",
    "    # Measure fitting time\n",
    "    end_time = time.time()\n",
    "    fit_times[sp] = end_time - start_time\n",
    "\n",
    "\n",
    "    best_val_accuracy = 0\n",
    "    best_lambda = 0  # regularization\n",
    "    best_support_size = 0\n",
    "    best_auc = 0\n",
    "\n",
    "    # Find the best lambda_0 and support_size based on validation accuracy\n",
    "    for index, row in gam.characteristics().iterrows():\n",
    "        support_size = row['support_size']\n",
    "        lambda_0 = row['l0']\n",
    "        y_pred = gam.predict(x=X_binary_val, lambda_0=lambda_0, gamma=0)\n",
    "        \n",
    "        # Convert probabilities to binary labels (0 or 1) using a threshold of 0.5\n",
    "        y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "        val_accuracy = accuracy_score(y_binary_val, y_pred_binary)\n",
    "        val_auc = roc_auc_score(y_binary_val, y_pred_binary)\n",
    "        \n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_lambda = lambda_0\n",
    "            best_support_size = support_size\n",
    "            best_auc = val_auc\n",
    "\n",
    "    print(f\"Best accuracy: {best_val_accuracy}, AUC: {best_auc}, lambda_0: {best_lambda}, support size: {best_support_size}\")\n",
    "\n",
    "    plot_shape_functions_fastsparse(gam=gam, binary_cols=X_binary.columns, continuous_df=X_train, lambda_0=best_lambda)\n",
    "    \n",
    "# Print fitting times\n",
    "print(\"\\nFitting Times (seconds):\")\n",
    "for sp, t in fit_times.items():\n",
    "    print(f\"{sp} smoothing parameters: {fit_times[sp]:.4f} sec\")\n",
    "\n",
    "# Plot fitting times separately\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(max_support_sizes, [fit_times[sp] for sp in max_support_sizes], marker='o')\n",
    "plt.xlabel('Number of Smoothing Parameters')\n",
    "plt.ylabel('Fitting Time (seconds)')\n",
    "plt.title('GAM Fitting Time vs. Number of Smoothing Parameters')\n",
    "plt.grid(True)\n",
    "plt.savefig('fastSparse_gam_timing_comparison.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
